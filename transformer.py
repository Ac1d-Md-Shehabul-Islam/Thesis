# -*- coding: utf-8 -*-
"""transformer.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1U5rb1cMozJJvkYrJbEqqTEDir10Spcju
"""

!pip install ktrain

# Commented out IPython magic to ensure Python compatibility.
# %reload_ext autoreload
# %autoreload 2
# %matplotlib inline
import os
os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID";
os.environ["CUDA_VISIBLE_DEVICES"] = "0";

# import ktrain
import pandas as pd
df = pd.DataFrame(columns=["Label","Posts"])

chunksize = 5000
for chunk in pd.read_csv("/content/drive/MyDrive/Thesis Papers/SMHD/final_cleaned_data.csv", chunksize=chunksize):
  df=df.append(chunk,ignore_index=True)

df["Label"].value_counts()

df_c = df[df["Label"] == "control"]
df_d = df[df["Label"] == "depression"]

df_c = df_c.sample(frac = 1)
df_c = df_c.sample(frac = 1).iloc[0:3000,]

df_d = df_d.sample(frac = 1)
df_d = df_d.sample(frac = 1).iloc[0:3000,]

# df_c = df_c.iloc[0:5000,]
# df_d = df_d.iloc[0:5000,]

def stripstr(x):
  return len(x.strip())==0

result = pd.concat([df_c, df_d], ignore_index=True, sort=False)
empty = result[result["Posts"].apply(stripstr)]
indexarr = empty.index
result.drop(index = indexarr, inplace=True)

result.describe()

result = result.sample(frac = 1)

import re
import pandas as pd

import nltk
nltk.download('stopwords')

stopwords = nltk.corpus.stopwords.words('english')
wn = nltk.WordNetLemmatizer()
nltk.download('wordnet')

def tokenize(txt):
  tokens = re.split('\W+',txt) # W means non-word characters and + means one or more
  return tokens

def lemmed(txt):
  text = [wn.lemmatize(word) for word in txt]
  return text

def remove_stopwords(txt):
  clean_msg = [word for word in txt if word not in stopwords]
  return clean_msg

result['Posts'] = result['Posts'].apply(lambda x: tokenize(x))
result['Posts'] = result['Posts'].apply(remove_stopwords)
result['Posts'] = result['Posts'].apply(lemmed)
result["Posts"]=result["Posts"].apply(lambda x: " ".join(x))

del(df_c)
del(df_d)
del(df)

x=result["Posts"]
y=result["Label"]

y

from sklearn.model_selection import train_test_split

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=42)

"""# ML Model"""

from ktrain import text

model_name = "distilbert-base-uncased"
trans = text.Transformer(model_name, maxlen = 512)#class_names=["control", "schizophrenia"]

train_data = trans.preprocess_train(x_train.tolist(), y_train.tolist())
test_data = trans.preprocess_test(x_test.tolist(), y_test.tolist())

model = trans.get_classifier()

learner = ktrain.get_learner(model, train_data=train_data, val_data=test_data, batch_size=16)

learner.lr_find(show_plot=True, max_epochs=4, suggest=True)

learner.fit_onecycle(1e-4,3)

learner.validate(class_names=["control","depression"])

learner.view_top_losses(n=8, preproc=trans)

x_test.loc[39]

predictor = ktrain.get_predictor(learner.model, preproc=trans)

xstr = "boy i'm very sad and hungry. I don't know what to do. i really miss her so much."

predictor.predict(xstr)