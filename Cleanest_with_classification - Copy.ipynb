{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cleanest_with_classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhVSUjVcpXGv"
      },
      "source": [
        "pip install ijson"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lzrqJNmaSUI"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15cDgGylPYZr"
      },
      "source": [
        "# def check(val):\n",
        "#   return (val=='depression' or val=='ptsd' or val=='schizophrenia' or val=='bipolar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKnwZ6ob4p7r"
      },
      "source": [
        "import pandas as pd\n",
        "# import collections\n",
        "# import ijson\n",
        "#from sklearn.feature_extraction.text import CountVectorizer\n",
        "#from sklearn.feature_extraction.text import TfidfTransformer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sTBQntmpkBi"
      },
      "source": [
        "# posts=[]\n",
        "# labels=[]\n",
        "# #c=0\n",
        "# with open(\"/content/drive/MyDrive/Thesis Papers/SMHD/train.jl\", \"rb\") as f:\n",
        "#   for line in f:\n",
        "#     # c=c+1\n",
        "#     # if(c==20):\n",
        "#     #   break\n",
        "#     item = ijson.items(line,'posts.item.text',multiple_values=True)\n",
        "    \n",
        "#     label = ijson.items(line,'label',multiple_values=True)\n",
        "#     for j in label:\n",
        "#       if(len(j)==2):\n",
        "#         for val in j:\n",
        "#           if(check(val)):\n",
        "#             labels.append(val)\n",
        "#             s=\"\"\n",
        "#             space=\" \"\n",
        "#             for i in item:\n",
        "#               s=s+space+i\n",
        "#             posts.append(s)\n",
        "#       else:\n",
        "#         if(check(j[0])):\n",
        "#           labels.append(j[0])\n",
        "#           s=\"\"\n",
        "#           space=\" \"\n",
        "#           for i in item:\n",
        "#             s=s+space+i\n",
        "#           posts.append(s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLEVn9fjpjtY"
      },
      "source": [
        "# df = pd.DataFrame({\"Label\": labels,\"Posts\": posts})\n",
        "\n",
        "# df.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cg3iNdbMVk6u"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Thesis Papers/SMHD/train_less.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pfa3BMqPXJ_S",
        "outputId": "3fc35ac7-37f6-4794-d331-c289f628b6fe"
      },
      "source": [
        "df[\"Label\"].value_counts()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "control          3000\n",
              "depression       2118\n",
              "bipolar          1062\n",
              "ptsd              330\n",
              "schizophrenia     148\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ac20XmSQivuH"
      },
      "source": [
        "**Logistic regression Start:**\n",
        "It goes out of memory!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHFh5iJteHRx"
      },
      "source": [
        "def _reciprocal_rank(true_labels: list, machine_preds: list):\n",
        "  tp_pos_list = [(idx + 1) for idx, r in enumerate(machine_preds) if r in true_labels]\n",
        "\n",
        "  rr = 0\n",
        "  if len(tp_pos_list) > 0:\n",
        "\n",
        "    first_pos_list = tp_pos_list[0]\n",
        "        \n",
        "        # rr = 1/rank\n",
        "    rr = 1 / float(first_pos_list)\n",
        "\n",
        "  return rr\n",
        "\n",
        "\n",
        "def compute_mrr_at_k(items:list):\n",
        "  rr_total = 0\n",
        "    \n",
        "  for item in items:   \n",
        "    rr_at_k = _reciprocal_rank(item[0],item[1])\n",
        "    rr_total = rr_total + rr_at_k\n",
        "    mrr = rr_total / 1/float(len(items))\n",
        "\n",
        "  return mrr\n",
        "\n",
        "def collect_preds(Y_test,Y_preds):\n",
        "    \n",
        "  pred_gold_list=[[[Y_test[idx]],pred] for idx,pred in enumerate(Y_preds)]\n",
        "  return pred_gold_list\n",
        "             \n",
        "def compute_accuracy(eval_items:list):\n",
        "  correct=0\n",
        "  total=0\n",
        "    \n",
        "  for item in eval_items:\n",
        "    true_pred=item[0]\n",
        "    machine_pred=set(item[1])\n",
        "        \n",
        "    for cat in true_pred:\n",
        "      if cat in machine_pred:\n",
        "        correct+=1\n",
        "        break\n",
        "    \n",
        "    \n",
        "  accuracy=correct/float(len(eval_items))\n",
        "  return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTjpFWPjdS9g"
      },
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "from sklearn import metrics\n",
        "import numpy as np\n",
        "\n",
        "def extract_features(df,field,training_data,testing_data):\n",
        "  # TF-IDF BASED FEATURE REPRESENTATION\n",
        "  tfidf_vectorizer=TfidfVectorizer(use_idf=True, max_df=0.95)\n",
        "  tfidf_vectorizer.fit_transform(training_data[field].values)\n",
        "        \n",
        "  train_feature_set=tfidf_vectorizer.transform(training_data[field].values)\n",
        "  test_feature_set=tfidf_vectorizer.transform(testing_data[field].values)\n",
        "        \n",
        "  return train_feature_set,test_feature_set,tfidf_vectorizer\n",
        "\n",
        "def get_top_k_predictions(model,X_test,k):\n",
        "    \n",
        "    # get probabilities instead of predicted labels, since we want to collect top 3\n",
        "  probs = model.predict_proba(X_test)\n",
        "\n",
        "    # GET TOP K PREDICTIONS BY PROB - note these are just index\n",
        "  best_n = np.argsort(probs, axis=1)[:,-k:]\n",
        "    \n",
        "    # GET CATEGORY OF PREDICTIONS\n",
        "  preds=[[model.classes_[predicted_cat] for predicted_cat in prediction] for prediction in best_n]\n",
        "    \n",
        "  preds=[ item[::-1] for item in preds]\n",
        "    \n",
        "  return preds\n",
        "   \n",
        "    \n",
        "def train_model(df,field=\"text_desc\",feature_rep=\"binary\",top_k=3):\n",
        "    \n",
        "    \n",
        "    \n",
        "    # GET A TRAIN TEST SPLIT (set seed for consistent results)\n",
        "  training_data, testing_data = train_test_split(df,random_state = 2000,)\n",
        "\n",
        "    # GET LABELS\n",
        "  Y_train=training_data['Label'].values\n",
        "  Y_test=testing_data['Label'].values\n",
        "     \n",
        "    # GET FEATURES\n",
        "  X_train,X_test,feature_transformer=extract_features(df,field,training_data,testing_data)\n",
        "\n",
        "    # INIT LOGISTIC REGRESSION CLASSIFIER\n",
        "  scikit_log_reg = LogisticRegression(verbose=1, solver='liblinear',random_state=0, C=5, penalty='l2',max_iter=1000)\n",
        "  model=scikit_log_reg.fit(X_train,Y_train)\n",
        "  \n",
        "  predictions = model.predict(X_test)\n",
        "\n",
        "    # GET TOP K PREDICTIONS\n",
        "  preds=get_top_k_predictions(model,X_test,top_k)\n",
        "\n",
        "    \n",
        "    # GET PREDICTED VALUES AND GROUND TRUTH INTO A LIST OF LISTS - for ease of evaluation\n",
        "  eval_items=collect_preds(Y_test,preds)\n",
        "  conf = metrics.classification_report(Y_test,predictions) \n",
        "  conf_matrix = metrics.confusion_matrix(Y_test,predictions) \n",
        "    # GET EVALUATION NUMBERS ON TEST SET -- HOW DID WE DO?\n",
        "  \n",
        "  accuracy=compute_accuracy(eval_items)\n",
        "  mrr_at_k=compute_mrr_at_k(eval_items)\n",
        "  \n",
        "    \n",
        "  return model,feature_transformer,accuracy,mrr_at_k,conf,conf_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSs52RwtWPNQ",
        "outputId": "9cf9ef1c-d967-4d1d-d555-c79f68295a88"
      },
      "source": [
        "field='Posts'\n",
        "feature_rep='tfidf'\n",
        "top_k=4\n",
        "\n",
        "model,transformer,accuracy,mrr_at_k,confusion,m=train_model(df,field=field,feature_rep=feature_rep,top_k=top_k)\n",
        "\n",
        "print(\"\\nAccuracy={0}; MRR={1}\".format(accuracy,mrr_at_k))\n",
        "print(confusion)\n",
        "print(m)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[LibLinear]\n",
            "Accuracy=1.0; MRR=0.7629107981220664\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      bipolar       0.41      0.06      0.10       268\n",
            "   depression       0.58      0.97      0.73       575\n",
            "         ptsd       0.50      0.01      0.02        92\n",
            "schizophrenia       0.00      0.00      0.00        59\n",
            "\n",
            "     accuracy                           0.58       994\n",
            "    macro avg       0.37      0.26      0.21       994\n",
            " weighted avg       0.49      0.58      0.45       994\n",
            "\n",
            "[[ 15 253   0   0]\n",
            " [ 16 558   1   0]\n",
            " [  4  87   1   0]\n",
            " [  2  57   0   0]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_IdRDCeWOnW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHzIRZxoJOpT"
      },
      "source": [
        "filter1=df[\"Label\"].isin([\"bipolar\",\"depression\"])\n",
        "newdf=df[filter1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eT-AeGi9MvEp",
        "outputId": "8b207c7f-7f58-4803-cb3c-677b03b76e2e"
      },
      "source": [
        "y.map({'bipolar': 0, 'depression': 1})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       1\n",
              "1       0\n",
              "2       0\n",
              "3       1\n",
              "4       1\n",
              "       ..\n",
              "6652    1\n",
              "6653    1\n",
              "6655    1\n",
              "6656    1\n",
              "6657    0\n",
              "Name: Label, Length: 3180, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRVWN8AnW9sO"
      },
      "source": [
        "def preprocess_text(sen):\n",
        "  # Removing html tags\n",
        "  sentence = remove_tags(sen)\n",
        "\n",
        "  # Remove punctuations and numbers\n",
        "  sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
        "\n",
        "  # Single character removal\n",
        "  sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
        "\n",
        "  # Removing multiple spaces\n",
        "  sentence = re.sub(r'\\s+', ' ', sentence)\n",
        "\n",
        "  return sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SauCBWqQXHT1"
      },
      "source": [
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8R77-Nr_XDdF"
      },
      "source": [
        "TAG_RE = re.compile(r'<[^>]+>')\n",
        "\n",
        "def remove_tags(text):\n",
        "  return TAG_RE.sub('', text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR4LTMB1XN1-"
      },
      "source": [
        "reviews = []\n",
        "sentences = list(newdf['Posts'])\n",
        "for sen in sentences:\n",
        "  reviews.append(preprocess_text(sen))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KY46Wi7tJWGz"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0Bb9Za_X4k9"
      },
      "source": [
        "x=reviews\n",
        "y=newdf[\"Label\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUFNJfJ5JahK"
      },
      "source": [
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IBEOU7fJeEi"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "schGXD7JK-ey"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RC-P6edhJgur"
      },
      "source": [
        "text_clf = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf', MultinomialNB()),])\n",
        "text_clf = text_clf.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRBPUBukJ7pD"
      },
      "source": [
        "# del labels\n",
        "# del posts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrSOMyU4KDQR"
      },
      "source": [
        "predictions = text_clf.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noXkBfyuZCeF"
      },
      "source": [
        "from sklearn import metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_vwbZiZKSE2",
        "outputId": "bf19e0fc-94ae-49e7-d70a-82ade02d1a94"
      },
      "source": [
        "print(metrics.confusion_matrix(y_test,predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0 304]\n",
            " [  0 650]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HB8XrfyKVzt",
        "outputId": "ef396930-318c-4898-cd43-6bbd545e4eae"
      },
      "source": [
        "print(metrics.classification_report(y_test,predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     bipolar       0.00      0.00      0.00       304\n",
            "  depression       0.68      1.00      0.81       650\n",
            "\n",
            "    accuracy                           0.68       954\n",
            "   macro avg       0.34      0.50      0.41       954\n",
            "weighted avg       0.46      0.68      0.55       954\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bue-4qTYLSgm",
        "outputId": "0b9bb9f1-a948-4d4e-8ba9-ed5c145ca11d"
      },
      "source": [
        "print(metrics.accuracy_score(y_test,predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6813417190775681\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}